#!/usr/bin/env python3
"""
ä¿®å¤YOLOæ ‡æ³¨æ–‡ä»¶ä¸­çš„æµ®ç‚¹æ•°ç±»åˆ«æ ‡ç­¾
å°†0.0ã€1.0ç­‰æµ®ç‚¹æ•°ç±»åˆ«æ ‡ç­¾è½¬æ¢ä¸º0ã€1ç­‰æ•´æ•°æ ¼å¼
"""
import os
import shutil

def fix_label_file(label_path, backup=True):
    """ä¿®å¤å•ä¸ªæ ‡æ³¨æ–‡ä»¶"""
    fixed_lines = []
    has_issue = False

    with open(label_path, 'r') as f:
        lines = f.readlines()

    for line in lines:
        parts = line.strip().split()
        if len(parts) != 5:
            fixed_lines.append(line)  # ä¿æŒåŸæ ·
            continue

        class_label = parts[0]

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®å¤
        if '.' in class_label:
            has_issue = True
            # è½¬æ¢ä¸ºæ•´æ•°
            class_id = int(float(class_label))
            # é‡å»ºè¡Œ
            fixed_line = f"{class_id} {parts[1]} {parts[2]} {parts[3]} {parts[4]}\n"
            fixed_lines.append(fixed_line)
        else:
            fixed_lines.append(line)

    # å¦‚æœå‘ç°é—®é¢˜ï¼Œè¿›è¡Œä¿®å¤
    if has_issue:
        # å¤‡ä»½åŸæ–‡ä»¶
        if backup:
            backup_path = label_path + '.backup'
            shutil.copy2(label_path, backup_path)

        # å†™å…¥ä¿®å¤åçš„å†…å®¹
        with open(label_path, 'w') as f:
            f.writelines(fixed_lines)

        return True

    return False


def fix_dataset(dataset_path, backup=True):
    """ä¿®å¤æ•´ä¸ªæ•°æ®é›†"""
    label_dir = os.path.join(dataset_path, "labels/Train")

    if not os.path.exists(label_dir):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ ‡ç­¾ç›®å½• {label_dir}")
        return

    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]

    print(f"\n{'='*70}")
    print(f"æ­£åœ¨ä¿®å¤æ•°æ®é›†: {dataset_path}")
    print(f"æ ‡ç­¾æ–‡ä»¶æ•°é‡: {len(label_files)}")
    print(f"å¤‡ä»½æ¨¡å¼: {'å¯ç”¨' if backup else 'ç¦ç”¨'}")
    print(f"{'='*70}\n")

    fixed_count = 0

    for label_file in label_files:
        label_path = os.path.join(label_dir, label_file)
        if fix_label_file(label_path, backup):
            fixed_count += 1
            print(f"âœ… å·²ä¿®å¤: {label_file}")

    print(f"\n{'='*70}")
    print(f"ğŸ“Š ä¿®å¤ç»“æœ")
    print(f"{'='*70}")
    print(f"æ€»æ–‡ä»¶æ•°: {len(label_files)}")
    print(f"ä¿®å¤æ–‡ä»¶æ•°: {fixed_count}")

    if fixed_count > 0:
        print(f"\nâœ… æˆåŠŸä¿®å¤ {fixed_count} ä¸ªæ–‡ä»¶ï¼")
        if backup:
            print(f"â„¹ï¸  åŸæ–‡ä»¶å·²å¤‡ä»½ä¸º .backup åç¼€")
    else:
        print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œæ— éœ€ä¿®å¤ï¼")
    print(f"{'='*70}\n")


if __name__ == "__main__":
    # ä¿®å¤å¢å¼ºåçš„æ•°æ®é›†
    datasets = [
        "/home/user/MERGE/FSW-MERGE_augmented_double",
        "/home/user/MERGE/FSW-MERGE_augmented_quadruple"
    ]

    print("\nâš ï¸  è­¦å‘Š: æ­¤è„šæœ¬å°†ä¿®æ”¹æ ‡æ³¨æ–‡ä»¶ï¼")
    print("å»ºè®®å…ˆä½¿ç”¨ verify_class_labels.py æ£€æŸ¥é—®é¢˜ã€‚")

    response = input("\næ˜¯å¦ç»§ç»­ä¿®å¤ï¼Ÿ(y/n): ")

    if response.lower() == 'y':
        for dataset in datasets:
            if os.path.exists(dataset):
                fix_dataset(dataset, backup=True)
            else:
                print(f"âš ï¸  è·³è¿‡: æ•°æ®é›†ä¸å­˜åœ¨ {dataset}\n")
    else:
        print("\nå·²å–æ¶ˆæ“ä½œã€‚")

