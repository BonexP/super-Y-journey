# 6. å®æˆ˜ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›å®Œæ•´çš„YOLOæ¨¡å‹ä¿®æ”¹å®æˆ˜ç¤ºä¾‹ï¼Œä»å®šä¹‰æ–°æ¨¡å—åˆ°è®­ç»ƒæµ‹è¯•çš„å®Œæ•´æµç¨‹ã€‚

## ğŸ¯ ç¤ºä¾‹1: æ·»åŠ SEæ³¨æ„åŠ›åˆ°YOLOv8

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•æ·»åŠ SEæ³¨æ„åŠ›æœºåˆ¶åˆ°YOLOv8æ¨¡å‹ã€‚

### æ­¥éª¤1: å®šä¹‰SEæ¨¡å—

**æ–‡ä»¶**: `ultralytics/nn/modules/block.py`

åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ï¼ˆçº¦2000è¡Œå·¦å³ï¼‰:

```python
class SEAttention(nn.Module):
    """Squeeze-and-Excitation attention module.

    This module applies channel-wise attention to enhance important features and suppress less useful ones.

    Args:
        channels (int): Number of input channels
        reduction (int): Reduction ratio for the bottleneck

    Examples:
        >>> se = SEAttention(256, reduction=16)
        >>> x = torch.randn(1, 256, 20, 20)
        >>> y = se(x)
        >>> print(y.shape)
        torch.Size([1, 256, 20, 20])
    """

    def __init__(self, channels, reduction=16):
        """Initialize SE attention with squeeze and excitation operations."""
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid(),
        )

    def forward(self, x):
        """Apply SE attention: squeeze global information and excite channel-wise."""
        b, c, _, _ = x.size()
        # Squeeze: global average pooling
        y = self.avg_pool(x).view(b, c)
        # Excitation: FC layers with sigmoid
        y = self.fc(y).view(b, c, 1, 1)
        # Scale: multiply input by attention weights
        return x * y.expand_as(x)
```

### æ­¥éª¤2: å¯¼å‡ºæ¨¡å—

**æ–‡ä»¶**: `ultralytics/nn/modules/block.py`

åœ¨ `__all__` å…ƒç»„ä¸­æ·»åŠ ï¼ˆçº¦15-55è¡Œï¼‰:

```python
__all__ = (
    "DFL",
    "HGBlock",
    # ... å…¶ä»–æ¨¡å—
    "SEAttention",  # æ·»åŠ è¿™ä¸€è¡Œ
)
```

**æ–‡ä»¶**: `ultralytics/nn/modules/__init__.py`

å¯¼å…¥å’Œå¯¼å‡ºæ¨¡å—:

```python
from .block import (
    # ... å…¶ä»–å¯¼å…¥
    SEAttention,  # æ·»åŠ è¿™ä¸€è¡Œ
)

__all__ = (
    # ... å…¶ä»–
    "SEAttention",  # æ·»åŠ è¿™ä¸€è¡Œ
)
```

### æ­¥éª¤3: æ³¨å†Œåˆ°æ¨¡å‹è§£æå™¨

**æ–‡ä»¶**: `ultralytics/nn/tasks.py`

åœ¨ `parse_model` å‡½æ•°çš„ `base_modules` ä¸­æ·»åŠ ï¼ˆçº¦1613-1654è¡Œï¼‰:

```python
base_modules = frozenset(
    {
        Classify,
        Conv,
        # ... å…¶ä»–æ¨¡å—
        SEAttention,  # æ·»åŠ è¿™ä¸€è¡Œ
    }
)
```

### æ­¥éª¤4: åˆ›å»ºé…ç½®æ–‡ä»¶

**æ–‡ä»¶**: `ultralytics/cfg/models/v8/yolov8-se.yaml`

```yaml
# YOLOv8 with SE Attention
# Adds SE attention after each C2f block for better feature representation

nc: 80 # number of classes
scales:
    # [depth, width, max_channels]
    n: [0.33, 0.25, 1024]
    s: [0.33, 0.50, 1024]
    m: [0.67, 0.75, 768]
    l: [1.00, 1.00, 512]
    x: [1.00, 1.25, 512]

# YOLOv8 backbone with SE
backbone:
    # [from, repeats, module, args]
    - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
    - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
    - [-1, 3, C2f, [128, True]]
    - [-1, 1, SEAttention, [128, 16]] # 3 - æ·»åŠ SEæ³¨æ„åŠ›

    - [-1, 1, Conv, [256, 3, 2]] # 4-P3/8
    - [-1, 6, C2f, [256, True]]
    - [-1, 1, SEAttention, [256, 16]] # 6 - æ·»åŠ SEæ³¨æ„åŠ›

    - [-1, 1, Conv, [512, 3, 2]] # 7-P4/16
    - [-1, 6, C2f, [512, True]]
    - [-1, 1, SEAttention, [512, 16]] # 9 - æ·»åŠ SEæ³¨æ„åŠ›

    - [-1, 1, Conv, [1024, 3, 2]] # 10-P5/32
    - [-1, 3, C2f, [1024, True]]
    - [-1, 1, SPPF, [1024, 5]] # 12
    - [-1, 1, SEAttention, [1024, 16]] # 13 - æ·»åŠ SEæ³¨æ„åŠ›

# YOLOv8 head
head:
    - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
    - [[-1, 9], 1, Concat, [1]] # cat backbone P4 (æ³¨æ„ç´¢å¼•å˜åŒ–)
    - [-1, 3, C2f, [512]] # 16

    - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
    - [[-1, 6], 1, Concat, [1]] # cat backbone P3 (æ³¨æ„ç´¢å¼•å˜åŒ–)
    - [-1, 3, C2f, [256]] # 19 (P3/8-small)

    - [-1, 1, Conv, [256, 3, 2]]
    - [[-1, 16], 1, Concat, [1]] # cat head P4
    - [-1, 3, C2f, [512]] # 22 (P4/16-medium)

    - [-1, 1, Conv, [512, 3, 2]]
    - [[-1, 13], 1, Concat, [1]] # cat head P5 (æ³¨æ„ç´¢å¼•å˜åŒ–)
    - [-1, 3, C2f, [1024]] # 25 (P5/32-large)

    - [[19, 22, 25], 1, Detect, [nc]] # Detect(P3, P4, P5)
```

### æ­¥éª¤5: æµ‹è¯•æ¨¡å‹æ„å»º

```python
from ultralytics import YOLO

# åŠ è½½è‡ªå®šä¹‰é…ç½®
model = YOLO("ultralytics/cfg/models/v8/yolov8-se.yaml")

# æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
model.info()

# æ‰“å°æ¨¡å‹ç»“æ„
print(model.model)
```

**é¢„æœŸè¾“å‡º**:

```
Model summary: 268 layers, 3500000 parameters, 3500000 gradients, 9.5 GFLOPs
```

### æ­¥éª¤6: è®­ç»ƒæ¨¡å‹

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO("ultralytics/cfg/models/v8/yolov8-se.yaml")

# è®­ç»ƒ
results = model.train(
    data="coco8.yaml",  # æ•°æ®é›†é…ç½®
    epochs=100,  # è®­ç»ƒè½®æ•°
    imgsz=640,  # å›¾åƒå¤§å°
    batch=16,  # æ‰¹é‡å¤§å°
    name="yolov8n-se",  # å®éªŒåç§°
    device=0,  # GPUè®¾å¤‡
)

# éªŒè¯
metrics = model.val()

# æ¨ç†
results = model("path/to/image.jpg")
```

---

## ğŸ¯ ç¤ºä¾‹2: åˆ›å»ºè½»é‡çº§Ghost-YOLO

ä½¿ç”¨GhostConvæ›¿æ¢æ™®é€šå·ç§¯ä»¥å‡å°‘å‚æ•°é‡ã€‚

### æ­¥éª¤1: åˆ›å»ºGhost-YOLOé…ç½®

**æ–‡ä»¶**: `ultralytics/cfg/models/v8/yolov8-ghost-custom.yaml`

```yaml
# Custom Ghost-YOLO - Ultra lightweight
nc: 80

backbone:
    # ä½¿ç”¨GhostConvæ›¿ä»£Convè¿›è¡Œä¸‹é‡‡æ ·
    - [-1, 1, GhostConv, [64, 3, 2]] # 0-P1/2
    - [-1, 1, GhostConv, [128, 3, 2]] # 1-P2/4
    - [-1, 3, C2f, [128, True]] # 2

    - [-1, 1, GhostConv, [256, 3, 2]] # 3-P3/8
    - [-1, 6, C2f, [256, True]] # 4

    - [-1, 1, GhostConv, [512, 3, 2]] # 5-P4/16
    - [-1, 6, C2f, [512, True]] # 6

    - [-1, 1, GhostConv, [1024, 3, 2]] # 7-P5/32
    - [-1, 3, C2f, [1024, True]] # 8
    - [-1, 1, SPPF, [1024, 5]] # 9

head:
    - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
    - [[-1, 6], 1, Concat, [1]]
    - [-1, 3, C2f, [512]] # 12

    - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
    - [[-1, 4], 1, Concat, [1]]
    - [-1, 3, C2f, [256]] # 15 (P3/8-small)

    - [-1, 1, GhostConv, [256, 3, 2]] # ä½¿ç”¨Ghostä¸‹é‡‡æ ·
    - [[-1, 12], 1, Concat, [1]]
    - [-1, 3, C2f, [512]] # 18 (P4/16-medium)

    - [-1, 1, GhostConv, [512, 3, 2]] # ä½¿ç”¨Ghostä¸‹é‡‡æ ·
    - [[-1, 9], 1, Concat, [1]]
    - [-1, 3, C2f, [1024]] # 21 (P5/32-large)

    - [[15, 18, 21], 1, Detect, [nc]]
```

### æ­¥éª¤2: å¯¹æ¯”æµ‹è¯•

```python
from ultralytics import YOLO

# æ ‡å‡†YOLOv8n
model_standard = YOLO("yolov8n.yaml")
print("Standard YOLOv8n:")
model_standard.info()

# Ghost-YOLO
model_ghost = YOLO("ultralytics/cfg/models/v8/yolov8-ghost-custom.yaml")
print("\nGhost-YOLO:")
model_ghost.info()

# å¯¹æ¯”å‚æ•°é‡å’ŒFLOPs
```

---

## ğŸ¯ ç¤ºä¾‹3: æ·»åŠ CoordConvåæ ‡å·ç§¯

### æ­¥éª¤1: å®ç°CoordConv

**æ–‡ä»¶**: `ultralytics/nn/modules/conv.py`

åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ :

```python
class CoordConv(nn.Module):
    """Coordinate Convolution adds position information to regular convolution.

    Reference: https://arxiv.org/abs/1807.03247

    Args:
        c1 (int): Input channels
        c2 (int): Output channels
        k (int): Kernel size
        s (int): Stride
        p (int, optional): Padding
        g (int): Groups
        d (int): Dilation
        act (bool | nn.Module): Activation function
        with_r (bool): Whether to include radius coordinate

    Examples:
        >>> coord_conv = CoordConv(3, 64, k=3, s=2)
        >>> x = torch.randn(1, 3, 640, 640)
        >>> y = coord_conv(x)
        >>> print(y.shape)
        torch.Size([1, 64, 320, 320])
    """

    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True, with_r=False):
        """Initialize CoordConv with coordinate information."""
        super().__init__()
        self.with_r = with_r
        # åæ ‡é€šé“: x, y, å¯é€‰çš„ r (radius)
        extra_channels = 3 if with_r else 2
        self.conv = Conv(c1 + extra_channels, c2, k, s, p, g, d, act)

    def add_coords(self, x):
        """Add x, y (and optionally r) coordinate channels to input."""
        batch_size, _, height, width = x.size()
        device = x.device
        dtype = x.dtype

        # Xåæ ‡
        xx_channel = torch.arange(width, dtype=dtype, device=device)
        xx_channel = xx_channel.repeat(1, height, 1)
        xx_channel = xx_channel / (width - 1) * 2 - 1  # å½’ä¸€åŒ–åˆ°[-1, 1]
        xx_channel = xx_channel.repeat(batch_size, 1, 1, 1)

        # Yåæ ‡
        yy_channel = torch.arange(height, dtype=dtype, device=device)
        yy_channel = yy_channel.repeat(1, width, 1).transpose(1, 2)
        yy_channel = yy_channel / (height - 1) * 2 - 1
        yy_channel = yy_channel.repeat(batch_size, 1, 1, 1)

        ret = torch.cat([x, xx_channel, yy_channel], dim=1)

        if self.with_r:
            # åŠå¾„åæ ‡
            rr = torch.sqrt(xx_channel**2 + yy_channel**2)
            ret = torch.cat([ret, rr], dim=1)

        return ret

    def forward(self, x):
        """Forward pass with coordinate augmentation."""
        x = self.add_coords(x)
        return self.conv(x)
```

### æ­¥éª¤2: å¯¼å‡ºå’Œæ³¨å†Œ

**åœ¨ `conv.py` çš„ `__all__` ä¸­**:

```python
__all__ = (
    "Conv",
    # ... å…¶ä»–
    "CoordConv",
)
```

**åœ¨ `modules/__init__.py` ä¸­**:

```python
from .conv import (
    # ... å…¶ä»–
    CoordConv,
)

__all__ = (
    # ... å…¶ä»–
    "CoordConv",
)
```

**åœ¨ `tasks.py` ä¸­**:

```python
base_modules = frozenset(
    {
        # ... å…¶ä»–
        CoordConv,
    }
)
```

### æ­¥éª¤3: åˆ›å»ºé…ç½®å¹¶æµ‹è¯•

**æ–‡ä»¶**: `ultralytics/cfg/models/v8/yolov8-coord.yaml`

```yaml
# YOLOv8 with CoordConv
nc: 80

backbone:
    - [-1, 1, CoordConv, [64, 3, 2, None, 1, 1, True, False]] # ä½¿ç”¨CoordConv
    - [-1, 1, Conv, [128, 3, 2]]
    - [-1, 3, C2f, [128, True]]
    - [-1, 1, Conv, [256, 3, 2]]
    - [-1, 6, C2f, [256, True]]
    - [-1, 1, Conv, [512, 3, 2]]
    - [-1, 6, C2f, [512, True]]
    - [-1, 1, Conv, [1024, 3, 2]]
    - [-1, 3, C2f, [1024, True]]
    - [-1, 1, SPPF, [1024, 5]]

# æ ‡å‡†headé…ç½®...
head:
    - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
    - [[-1, 6], 1, Concat, [1]]
    - [-1, 3, C2f, [512]]

    - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
    - [[-1, 4], 1, Concat, [1]]
    - [-1, 3, C2f, [256]]

    - [-1, 1, Conv, [256, 3, 2]]
    - [[-1, 12], 1, Concat, [1]]
    - [-1, 3, C2f, [512]]

    - [-1, 1, Conv, [512, 3, 2]]
    - [[-1, 9], 1, Concat, [1]]
    - [-1, 3, C2f, [1024]]

    - [[15, 18, 21], 1, Detect, [nc]]
```

**æµ‹è¯•**:

```python
import torch

from ultralytics import YOLO

model = YOLO("ultralytics/cfg/models/v8/yolov8-coord.yaml")
model.info()

# æµ‹è¯•å‰å‘ä¼ æ’­
x = torch.randn(1, 3, 640, 640)
with torch.no_grad():
    y = model(x)
print(f"Output: {len(y)} tensors")
```

---

## ğŸ¯ ç¤ºä¾‹4: ç»„åˆå¤šç§æ”¹è¿›

åˆ›å»ºä¸€ä¸ªç»“åˆSEæ³¨æ„åŠ›ã€Ghostå·ç§¯å’Œæ”¹è¿›FPNçš„é«˜çº§æ¨¡å‹ã€‚

### é…ç½®æ–‡ä»¶

**æ–‡ä»¶**: `ultralytics/cfg/models/v8/yolov8-advanced.yaml`

```yaml
# Advanced YOLOv8 with multiple enhancements
nc: 80

backbone:
    # ä½¿ç”¨Ghostå‡å°‘å‚æ•°
    - [-1, 1, GhostConv, [64, 3, 2]]
    - [-1, 1, GhostConv, [128, 3, 2]]
    - [-1, 3, C2f, [128, True]]
    - [-1, 1, SEAttention, [128, 16]] # SEæ³¨æ„åŠ›

    - [-1, 1, GhostConv, [256, 3, 2]]
    - [-1, 6, C2f, [256, True]]
    - [-1, 1, CBAM, [256]] # CBAMæ³¨æ„åŠ›

    - [-1, 1, Conv, [512, 3, 2]]
    - [-1, 6, C2f, [512, True]]
    - [-1, 1, SEAttention, [512, 16]]

    - [-1, 1, Conv, [1024, 3, 2]]
    - [-1, 3, C2f, [1024, True]]
    - [-1, 1, SPPF, [1024, 5]]
    - [-1, 1, CBAM, [1024]] # CBAMæ³¨æ„åŠ›

head:
    # BiFPNé£æ ¼çš„ç‰¹å¾èåˆ
    - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
    - [[-1, 9], 1, Concat, [1]]
    - [-1, 3, C2f, [512]]
    - [-1, 1, SEAttention, [512, 16]] # headä¸­ä¹ŸåŠ æ³¨æ„åŠ›

    - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
    - [[-1, 6], 1, Concat, [1]]
    - [-1, 3, C2f, [256]]
    - [-1, 1, SEAttention, [256, 16]]

    - [-1, 1, Conv, [256, 3, 2]]
    - [[-1, 16], 1, Concat, [1]]
    - [-1, 3, C2f, [512]]

    - [-1, 1, Conv, [512, 3, 2]]
    - [[-1, 13], 1, Concat, [1]]
    - [-1, 3, C2f, [1024]]

    - [[19, 22, 25], 1, Detect, [nc]]
```

### è®­ç»ƒè„šæœ¬

```python
import torch

from ultralytics import YOLO

# æ£€æŸ¥CUDAå¯ç”¨æ€§
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# åŠ è½½æ¨¡å‹
model = YOLO("ultralytics/cfg/models/v8/yolov8-advanced.yaml")

# æ‰“å°æ¨¡å‹ä¿¡æ¯
print("\n=== Model Information ===")
model.info()

# è®­ç»ƒé…ç½®
train_config = {
    "data": "coco128.yaml",  # ä½¿ç”¨COCO128è¿›è¡Œå¿«é€Ÿæµ‹è¯•
    "epochs": 50,
    "imgsz": 640,
    "batch": 16,
    "name": "yolov8-advanced",
    "device": device,
    "workers": 8,
    "optimizer": "Adam",
    "lr0": 0.001,
    "patience": 10,
    "save": True,
    "plots": True,
}

# å¼€å§‹è®­ç»ƒ
print("\n=== Starting Training ===")
results = model.train(**train_config)

# éªŒè¯
print("\n=== Validation ===")
metrics = model.val()

print(f"\nmAP50: {metrics.box.map50:.3f}")
print(f"mAP50-95: {metrics.box.map:.3f}")

# å¯¼å‡ºæ¨¡å‹
print("\n=== Exporting Model ===")
model.export(format="onnx", dynamic=True, simplify=True)
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”è„šæœ¬

```python
import time

import torch

from ultralytics import YOLO


def benchmark_model(model_path, name, imgsz=640):
    """Benchmark a YOLO model."""
    print(f"\n{'=' * 50}")
    print(f"Benchmarking: {name}")
    print(f"{'=' * 50}")

    # åŠ è½½æ¨¡å‹
    model = YOLO(model_path)
    model.info(verbose=False)

    # å‡†å¤‡è¾“å…¥
    device = "cuda" if torch.cuda.is_available() else "cpu"
    dummy_input = torch.randn(1, 3, imgsz, imgsz).to(device)
    model.model.to(device)

    # é¢„çƒ­
    with torch.no_grad():
        for _ in range(10):
            _ = model.model(dummy_input)

    # æµ‹é€Ÿ
    num_iterations = 100
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    start = time.time()

    with torch.no_grad():
        for _ in range(num_iterations):
            _ = model.model(dummy_input)

    torch.cuda.synchronize() if torch.cuda.is_available() else None
    end = time.time()

    avg_time = (end - start) / num_iterations * 1000  # ms
    fps = 1000 / avg_time

    print(f"Average inference time: {avg_time:.2f} ms")
    print(f"FPS: {fps:.1f}")

    return avg_time, fps


# å¯¹æ¯”ä¸åŒæ¨¡å‹
models = {
    "YOLOv8n": "yolov8n.yaml",
    "YOLOv8n-SE": "ultralytics/cfg/models/v8/yolov8-se.yaml",
    "YOLOv8n-Ghost": "ultralytics/cfg/models/v8/yolov8-ghost-custom.yaml",
    "YOLOv8n-Advanced": "ultralytics/cfg/models/v8/yolov8-advanced.yaml",
}

results = {}
for name, path in models.items():
    try:
        avg_time, fps = benchmark_model(path, name)
        results[name] = {"time": avg_time, "fps": fps}
    except Exception as e:
        print(f"Error benchmarking {name}: {e}")

# æ‰“å°å¯¹æ¯”è¡¨
print(f"\n{'=' * 60}")
print(f"{'Model':<25} {'Time (ms)':<15} {'FPS':<10}")
print(f"{'=' * 60}")
for name, metrics in results.items():
    print(f"{name:<25} {metrics['time']:<15.2f} {metrics['fps']:<10.1f}")
```

---

## âœ… éªŒè¯æ¸…å•

åœ¨å®Œæˆä¿®æ”¹åï¼Œä½¿ç”¨ä»¥ä¸‹æ¸…å•éªŒè¯ï¼š

- [ ] æ¨¡å—èƒ½æˆåŠŸå¯¼å…¥
- [ ] æ¨¡å‹èƒ½æ­£å¸¸æ„å»º
- [ ] å‰å‘ä¼ æ’­æ— é”™è¯¯
- [ ] å‚æ•°é‡å’ŒFLOPsç¬¦åˆé¢„æœŸ
- [ ] èƒ½æ­£å¸¸è®­ç»ƒï¼ˆè‡³å°‘1ä¸ªepochï¼‰
- [ ] èƒ½æ­£å¸¸éªŒè¯
- [ ] èƒ½å¯¼å‡ºä¸ºONNX/TorchScript
- [ ] æ¨ç†é€Ÿåº¦å¯æ¥å—

---

## ğŸ“ æ€»ç»“

é€šè¿‡è¿™äº›å®æˆ˜ç¤ºä¾‹ï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

1. âœ… å®šä¹‰æ–°çš„å·ç§¯å’Œæ³¨æ„åŠ›æ¨¡å—
2. âœ… æ­£ç¡®æ³¨å†Œæ¨¡å—åˆ°è§£æå™¨
3. âœ… åˆ›å»ºè‡ªå®šä¹‰YAMLé…ç½®
4. âœ… è®­ç»ƒå’Œæµ‹è¯•ä¿®æ”¹åçš„æ¨¡å‹
5. âœ… è¿›è¡Œæ€§èƒ½å¯¹æ¯”å’Œä¼˜åŒ–

ç»§ç»­æ¢ç´¢å’Œå®éªŒï¼Œåˆ›å»ºæœ€é€‚åˆä½ ä»»åŠ¡çš„YOLOæ¨¡å‹ï¼
